{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import collections\n",
    "from collections import defaultdict\n",
    "\n",
    "from shutil import copy\n",
    "from shutil import copytree, rmtree\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as img\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to download data and extract\n",
    "\n",
    "def get_data_extract():\n",
    "    if \"food-101\" in os.listdir():\n",
    "        print(\"Dataset already exists\")\n",
    "    else:\n",
    "        tf.keras.utils.get_file(\n",
    "        'food-101.tar.gz',\n",
    "        'http://data.vision.ee.ethz.ch/cvl/food-101.tar.gz',\n",
    "        cache_subdir='/content',\n",
    "        extract=True,\n",
    "        archive_format='tar',\n",
    "        cache_dir=None\n",
    "        )\n",
    "        print(\"Dataset downloaded and extracted!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data and extract it to folder\n",
    "get_data_extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the data, showing one image per class from 101 classes\n",
    "rows = 17\n",
    "cols = 6\n",
    "fig, ax = plt.subplots(rows, cols, figsize=(25,25))\n",
    "fig.suptitle(\"Showing one random image from each class\", y=1.05, fontsize=24) # Adding  y=1.05, fontsize=24 helped me fix the suptitle overlapping with axes issue\n",
    "data_dir = \"food-101/images/\"\n",
    "foods_sorted = sorted(os.listdir(data_dir))\n",
    "food_id = 0\n",
    "for i in range(rows):\n",
    "    for j in range(cols):\n",
    "        try:\n",
    "            food_selected = foods_sorted[food_id] \n",
    "            food_id += 1\n",
    "    except:\n",
    "        break\n",
    "    food_selected_images = os.listdir(os.path.join(data_dir,food_selected)) # returns the list of all files present in each food category\n",
    "    food_selected_random = np.random.choice(food_selected_images) # picks one food item from the list as choice, takes a list and returns one random item\n",
    "    img = plt.imread(os.path.join(data_dir,food_selected, food_selected_random))\n",
    "    ax[i][j].imshow(img)\n",
    "    ax[i][j].set_title(food_selected, pad = 10)\n",
    "    \n",
    "plt.setp(ax, xticks=[],yticks=[])\n",
    "plt.tight_layout()\n",
    "# https://matplotlib.org/users/tight_layout_guide.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper method to split dataset into train and test folders\n",
    "def prepare_data(filepath, src,dest):\n",
    "    classes_images = defaultdict(list)\n",
    "    with open(filepath, 'r') as txt:\n",
    "        paths = [read.strip() for read in txt.readlines()]\n",
    "        for p in paths:\n",
    "            food = p.split('/')\n",
    "            classes_images[food[0]].append(food[1] + '.jpg')\n",
    "\n",
    "    for food in classes_images.keys():\n",
    "        print(\"\\nCopying images into \",food)\n",
    "        if not os.path.exists(os.path.join(dest,food)):\n",
    "            os.makedirs(os.path.join(dest,food))\n",
    "        for i in classes_images[food]:\n",
    "            copy(os.path.join(src,food,i), os.path.join(dest,food,i))\n",
    "    print(\"Copying Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare train dataset by copying images from food-101/images to food-101/train using the file train.txt\n",
    "print(\"Creating train data...\")\n",
    "prepare_data('food-101/meta/train.txt', 'food-101/images', 'food-101/train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare test data by copying images from food-101/images to food-101/test using the file test.txt\n",
    "print(\"Creating test data...\")\n",
    "prepare_data('food-101/meta/test.txt', 'food-101/images', 'food-101/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how many files are in the train folder\n",
    "\n",
    "train_files = sum([len(files) for i, j, files in os.walk(\"food-101/train\")])\n",
    "print(\"Total number of samples in train folder\")\n",
    "print(train_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how many files are in the test folder\n",
    "test_files = sum([len(files) for i, j, files in os.walk(\"food-101/test\")])\n",
    "print(\"Total number of samples in test folder\")\n",
    "print(test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of all 101 types of foods(sorted alphabetically)\n",
    "foods_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper method to create train_mini and test_mini data samples\n",
    "def dataset_mini(food_list, src, dest):\n",
    "    if os.path.exists(dest):\n",
    "        rmtree(dest) # removing dataset_mini(if it already exists) folders so that we will have only the classes that we want\n",
    "    os.makedirs(dest)\n",
    "    for food_item in food_list :\n",
    "        print(\"Copying images into\",food_item)\n",
    "        copytree(os.path.join(src,food_item), os.path.join(dest,food_item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# picking 3 food items and generating separate data folders for the same\n",
    "food_list = ['samosa','pizza','omelette']\n",
    "src_train = 'food-101/train'\n",
    "dest_train = 'food-101/train_mini'\n",
    "src_test = 'food-101/test'\n",
    "dest_test = 'food-101/test_mini'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating train data folder with new classes\")\n",
    "dataset_mini(food_list, src_train, dest_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total number of samples in train folder\")\n",
    "train_files = sum([len(files) for i, j, files in os.walk(\"food-101/train_mini\")])\n",
    "print(train_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating test data folder with new classes\")\n",
    "dataset_mini(food_list, src_test, dest_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total number of samples in test folder\")\n",
    "test_files = sum([len(files) for i, j, files in os.walk(\"food-101/test_mini\")])\n",
    "print(test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(n_classes,num_epochs, nb_train_samples,nb_validation_samples):\n",
    "    K.clear_session()\n",
    "\n",
    "    img_width, img_height = 299, 299\n",
    "    train_data_dir = 'food-101/train_mini'\n",
    "    validation_data_dir = 'food-101/test_mini'\n",
    "    batch_size = 16\n",
    "    bestmodel_path = 'bestmodel_'+str(n_classes)+'class.hdf5'\n",
    "    trainedmodel_path = 'trainedmodel_'+str(n_classes)+'class.hdf5'\n",
    "    history_path = 'history_'+str(n_classes)+'.log'\n",
    "\n",
    "    train_datagen = ImageDataGenerator(\n",
    "      preprocessing_function=preprocess_input,\n",
    "      shear_range=0.2,\n",
    "      zoom_range=0.2,\n",
    "      horizontal_flip=True)\n",
    "\n",
    "    test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "      train_data_dir,\n",
    "      target_size=(img_height, img_width),\n",
    "      batch_size=batch_size,\n",
    "      class_mode='categorical')\n",
    "\n",
    "    validation_generator = test_datagen.flow_from_directory(\n",
    "      validation_data_dir,\n",
    "      target_size=(img_height, img_width),\n",
    "      batch_size=batch_size,\n",
    "      class_mode='categorical')\n",
    "\n",
    "\n",
    "    inception = InceptionV3(weights='imagenet', include_top=False)\n",
    "    x = inception.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(128,activation='relu')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "\n",
    "    predictions = Dense(n_classes,kernel_regularizer=regularizers.l2(0.005), activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=inception.input, outputs=predictions)\n",
    "    model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    checkpoint = ModelCheckpoint(filepath=bestmodel_path, verbose=1, save_best_only=True)\n",
    "    csv_logger = CSVLogger(history_path)\n",
    "\n",
    "    history = model.fit_generator(train_generator,\n",
    "                      steps_per_epoch = nb_train_samples // batch_size,\n",
    "                      validation_data=validation_generator,\n",
    "                      validation_steps=nb_validation_samples // batch_size,\n",
    "                      epochs=num_epochs,\n",
    "                      verbose=1,\n",
    "                      callbacks=[csv_logger, checkpoint])\n",
    "\n",
    "    model.save(trainedmodel_path)\n",
    "    class_map = train_generator.class_indices\n",
    "    return history, class_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model with data from 3 classes\n",
    "n_classes = 3\n",
    "epochs = 5\n",
    "nb_train_samples = train_files\n",
    "nb_validation_samples = test_files\n",
    "\n",
    "history, class_map_3 = train_model(n_classes,epochs, nb_train_samples,nb_validation_samples)\n",
    "print(class_map_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracy(history,title):\n",
    "    plt.title(title)\n",
    "    plt.plot(history.history['accuracy']) # change acc to accuracy if testing TF 2.0\n",
    "    plt.plot(history.history['val_accuracy']) # change val_accuracy if testing TF 2.0\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train_accuracy', 'validation_accuracy'], loc='best')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_loss(history,title):\n",
    "    plt.title(title)\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train_loss', 'validation_loss'], loc='best')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_accuracy(history,'FOOD101-Inceptionv3')\n",
    "plot_loss(history,'FOOD101-Inceptionv3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Loading the best saved model to make predictions\n",
    "\n",
    "K.clear_session()\n",
    "model_best = load_model('bestmodel_3class.hdf5',compile = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여기부터 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df =pd.read_csv('/content/food.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_class(model, images, show = True):\n",
    "    for img in images:\n",
    "        img = image.load_img(img, target_size=(299, 299))\n",
    "        img = image.img_to_array(img)                    \n",
    "        img = np.expand_dims(img, axis=0)         \n",
    "        img = preprocess_input(img)                                      \n",
    "\n",
    "        pred = model.predict(img)\n",
    "        index = np.argmax(pred)\n",
    "        food_list.sort()\n",
    "        pred_value = food_list[index]\n",
    "        recipe=df.loc[0,pred_value] #변경\n",
    "        #print(pred)\n",
    "        if show:\n",
    "            plt.imshow(img[0])                           \n",
    "            plt.axis('off')\n",
    "            plt.title(pred_value)\n",
    "            plt.show()\n",
    "            print(recipe) #변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a list of images and test the trained model\n",
    "!wget -O samosa.jpg http://veggiefoodrecipes.com/wp-content/uploads/2016/05/lentil-samosa-recipe-01.jpg\n",
    "!wget -O applepie.jpg https://acleanbake.com/wp-content/uploads/2017/10/Paleo-Apple-Pie-with-Crumb-Topping-gluten-free-grain-free-dairy-free-15.jpg\n",
    "images = []\n",
    "#images.append('applepie.jpg')\n",
    "images.append('samosa.jpg')\n",
    "predict_class(model_best, images, True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
